# Copyright The OpenTelemetry Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import inspect
# TODO: generated by windsurf, need verification

import logging
import uuid
from timeit import default_timer
from typing import Any, List, Optional

from opentelemetry.genai.sdk.api import TelemetryClient
from opentelemetry.genai.sdk.data import Error
from opentelemetry.instrumentation.langchain.config import Config
from opentelemetry.instrumentation.langchain.utils import dont_throw, should_collect_content
from opentelemetry.semconv._incubating.attributes import gen_ai_attributes
from opentelemetry.trace import SpanKind, get_tracer, get_current_span
from opentelemetry.context import get_current
from opentelemetry.semconv.schemas import Schemas

logger = logging.getLogger(__name__)


def embed_query_wrapper(telemetry_client: TelemetryClient):
    """Wrap the embed_query method of Embeddings classes to trace it."""
    
    @dont_throw
    def traced_method(wrapped, instance, args, kwargs):
        if Config.is_instrumentation_suppressed():
            return wrapped(*args, **kwargs)
        
        # Extract the query text from args/kwargs
        query = args[0] if args else kwargs.get('text', '')
        
        # Get model information from the instance
        model_name = getattr(instance, 'model', None) or getattr(instance, 'model_name', None) or instance.__class__.__name__
        
        # Get the current context to ensure we're under the parent span
        current_context = get_current()
        current_span = get_current_span(current_context)
        
        # Extract parent_run_id from the current span context if available
        parent_run_id = None
        if current_span and current_span.is_recording():
            # Try to get the run_id from span attributes or context
            span_context = current_span.get_span_context()
            if hasattr(span_context, 'span_id'):
                # Convert span_id to UUID format for parent_run_id
                # Note: This is a simplified approach - in a real implementation,
                # you might want to store the actual run_id in span attributes
                parent_run_id = uuid.UUID(int=span_context.span_id)
        
        # Create a tracer to start the embedding span as a child of the current context
        tracer = get_tracer(__name__, schema_url=Schemas.V1_28_0.value)
        
        span_name = f"langchain.embeddings.embed_query"
        span_attributes = {
            gen_ai_attributes.GEN_AI_OPERATION_NAME: gen_ai_attributes.GenAiOperationNameValues.EMBEDDINGS,
            gen_ai_attributes.GEN_AI_SYSTEM: "langchain",
            gen_ai_attributes.GEN_AI_REQUEST_MODEL: model_name,
        }
        
        # Add query content if content collection is enabled
        if should_collect_content() and query:
            span_attributes["gen_ai.prompt"] = query
        
        # Start the embedding span as a child of the current context (parent span)
        with tracer.start_as_current_span(
            name=span_name,
            kind=SpanKind.CLIENT,
            attributes=span_attributes,
            context=current_context
        ) as embedding_span:
            # Use the current span ID as the run_id for internal embedding tracking
            run_id = embedding_span.get_span_context().span_id
            telemetry_client.start_embedding(run_id, "langchain", model_name, parent_run_id)

            try:
                result = wrapped(*args, **kwargs)
                
                # Add embedding dimension to span if available
                if embedding_span.is_recording() and result:
                    if isinstance(result, list) and len(result) > 0:
                        embedding_span.set_attribute("gen_ai.embedding.dimension", len(result))
                
                telemetry_client.stop_embedding(run_id, len(result))
                return result
                
            except Exception as ex:
                embedding_error = Error(message=str(ex), type=type(ex))
                telemetry_client.fail_embedding(run_id, embedding_error)
                
                # Record the exception in the span
                embedding_span.record_exception(ex)
                embedding_span.set_status(status="ERROR", description=str(ex))
                raise



    #     # Get tracer from telemetry client
    #     tracer = getattr(telemetry_client, '_tracer', None)
    #     if not tracer:
    #         # Fallback to creating a tracer if not available
    #         from opentelemetry.trace import get_tracer
    #         tracer = get_tracer(__name__)
    #
    #     with tracer.start_as_current_span(
    #         name=span_name,
    #         kind=SpanKind.CLIENT,
    #         end_on_exit=False,
    #     ) as span:
    #         start_time = default_timer()
    #         error_type = None
    #         result = None
    #
    #         try:
    #             result = wrapped(*args, **kwargs)
    #
    #             # Add response attributes
    #             if span.is_recording() and result:
    #                 if isinstance(result, list) and len(result) > 0:
    #                     span.set_attribute("gen_ai.embedding.dimension", len(result))
    #
    #             span.end()
    #             return result
    #
    #         except Exception as error:
    #             error_type = type(error).__qualname__
    #             span.record_exception(error)
    #             span.set_status(status="ERROR", description=str(error))
    #             span.end()
    #             raise
    #         finally:
    #             duration = max((default_timer() - start_time), 0)
    #
    #             # Record metrics if available
    #             if hasattr(telemetry_client, '_meter') and telemetry_client._meter:
    #                 common_attributes = {
    #                     gen_ai_attributes.GEN_AI_OPERATION_NAME: "embed_query",
    #                     gen_ai_attributes.GEN_AI_SYSTEM: "langchain",
    #                     gen_ai_attributes.GEN_AI_REQUEST_MODEL: model_name,
    #                 }
    #
    #                 if error_type:
    #                     common_attributes["error.type"] = error_type
    #
    #                 # Create histogram if it doesn't exist
    #                 if not hasattr(telemetry_client, '_embedding_duration_histogram'):
    #                     telemetry_client._embedding_duration_histogram = telemetry_client._meter.create_histogram(
    #                         name="gen_ai.client.operation.duration",
    #                         description="Duration of embedding operations",
    #                         unit="s",
    #                     )
    #
    #                 telemetry_client._embedding_duration_histogram.record(
    #                     duration,
    #                     attributes=common_attributes,
    #                 )
    #
    return traced_method